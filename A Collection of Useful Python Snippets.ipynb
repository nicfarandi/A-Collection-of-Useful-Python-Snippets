{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Collection of Useful Python Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once in every environment\n",
    "!pip install wordcloud\n",
    "!pip install seaborn\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Local .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# where to find file ID\n",
    "# https://drive.google.com/file/d/13x2amKB3smbbh0P3yk2djhqBF-D5R4Dz/view?usp=sharing\n",
    "#                            id = 13x2amKB3smbbh0P3yk2djhqBF-D5R4Dz\n",
    "\n",
    "file_id = \"\" # input file ID\n",
    "file_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "response = requests.get(file_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = BytesIO(response.content)\n",
    "    data = pd.read_csv(content)\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.head()\n",
    "data.tail()\n",
    "data.describe().T\n",
    "data.isnull().sum()\n",
    "data.isna().sum()\n",
    "data.describe().T.plot(kind='bar')\n",
    "data.describe(include='all').T\n",
    "data.duplicated().sum()\n",
    "data.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Y'].value_counts())\n",
    "data['Y'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix (bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corrwith(data[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corr = data.corr(method = 'pearson')\n",
    "mask = np.array(corr)\n",
    "\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig, ax = plt.subplots(figsize = (15,12))\n",
    "fig.set_size_inches(70,12)\n",
    "sns.heatmap(corr, mask = mask, vmax = 0.9, square = True, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.select_dtypes(include=np.number).columns  \n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih fitur dengan tingkat korelasi yang tinggi dengan fitur target: kolom 'Class'\n",
    "correlated_features = corr['Y'].sort_values(ascending=False, key=lambda x: abs(x))\n",
    "print(\"Features sorted by correlation with the target:\\n\", correlated_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names of All Non-Numeric Columns along with unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = data.select_dtypes(exclude='number').columns\n",
    "for col in non_numeric_columns:\n",
    "    print(f\"Unique values in column {col}:\")\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of All Columns (Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(data, kind='reg', plot_kws={'line_kws': {'color': 'red'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cathegories of interviewed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "categories = ['X', 'Y']\n",
    "n_row = 2 # number of rows\n",
    "n_col = 2 # number of columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_row, ncols=n_col, figsize=(12, 8))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    row = i // n_col\n",
    "    col = i % n_col\n",
    "\n",
    "    counts = data[category].value_counts()\n",
    "    \n",
    "    axes[row, col].bar(counts.index, counts)\n",
    "    axes[row, col].set_title(f'{category} distribution')\n",
    "    axes[row, col].set_xlabel(category)\n",
    "    axes[row, col].set_ylabel('count')\n",
    "    \n",
    "    axes[row, col].set_xticklabels(counts.index, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import express\n",
    "\n",
    "for column in ['X', 'Y']:\n",
    "    express.histogram(data_frame=data, x=column).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "reviews_text = ' '.join(data['Y'].dropna())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(reviews_text)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud of Reviews')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Rows with Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with any NaN values\n",
    "null_rows = data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Display the result\n",
    "null_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Non-Numeric to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'x': 1, 'y': 2, 'z': 3} \n",
    "columns_to_map = ['col1', 'col2', 'col3']\n",
    "for column in columns_to_map:\n",
    "    data[column] = data[column].map(mapping)\n",
    "    # data[column] = data[column].map(mapping).fillna(0) # if null = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['X', 'Y']\n",
    "data.drop(columns, axis=1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Row Based on Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Y'] != xyz] # xyz is the condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['X', 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ycol = \"Y\" # y column\n",
    "X = data.drop(columns=[ycol])\n",
    "y = data[ycol]\n",
    "r_state = 42\n",
    "t_size = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                \ttest_size=t_size,\n",
    "                                                \trandom_state=r_state,\n",
    "                                                \t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X_test\n",
    "y = y_test\n",
    "r_state = 42\n",
    "t_size = 0.2\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X, y,\n",
    "                                            \ttest_size=t_size,\n",
    "                                            \trandom_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "y = y_test\n",
    "r_state = 42\n",
    "t_size = 0.2\n",
    "v_size = 0.5\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y,\n",
    "                                                \ttest_size=t_size,\n",
    "                                                \trandom_state=r_state,)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp,\n",
    "                                            \ttest_size=t_size,\n",
    "                                            \trandom_state=r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple model with accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "# from sklearn.() import () # import model\n",
    "\n",
    "model = () # declare model here\n",
    "model.fit(X_train, y_train)\n",
    "# model_pred_val = model.predict(X_val)\n",
    "model_pred_test= model.predict(X_test)\n",
    "# model_pred_val = pd.DataFrame(model_pred_val)\n",
    "model_pred_test = pd.DataFrame(model_pred_test)\n",
    "accuracy = accuracy_score(y_test, model_pred_test)\n",
    "precision = precision_score(y_test, model_pred_test)\n",
    "recall = recall_score(y_test, model_pred_test)\n",
    "\n",
    "print(\"Model X: \")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "models = [model]\n",
    "labels = ['Model X']\n",
    "\n",
    "for model, label in zip(models, labels):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix - {label}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\", input_dim=X_train.shape[1]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.02)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.02)),\n",
    "    tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mean_squared_error'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=256, validation_data=(X_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
